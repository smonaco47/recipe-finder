{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc720845-c443-494f-8a98-f10992faced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import pickle\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import gc\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8f1c34-4464-49db-99e2-3a74d498a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recipes_one_hot = pd.read_pickle('../cleaned_data/recipe_encoded_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f71ba-e00e-430c-b1bc-26f87be4882e",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39bc627a-6126-4bfd-ae9a-10d46f9b9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CLUSTERS = 2\n",
    "MAX_CLUSTERS =30\n",
    "STEP = 2\n",
    "MAX_ITER = 10000\n",
    "ROOT_FOLDER = '../temp_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "526fbf0e-ebcd-40fd-81d2-c8e6661e6a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 2 clusters\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "Training 4 clusters\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "Training 6 clusters\n",
      "Training 8 clusters\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "Training 10 clusters\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "Training 12 clusters\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "Training 14 clusters\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "Training 16 clusters\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "Training 18 clusters\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "Training 20 clusters\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "Training 22 clusters\n",
      "[MiniBatchKMeans] Reassigning 3 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 3 cluster centers.\n",
      "Training 24 clusters\n",
      "[MiniBatchKMeans] Reassigning 4 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 4 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 2 cluster centers.\n",
      "Training 26 clusters\n",
      "[MiniBatchKMeans] Reassigning 4 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 2 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 3 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 2 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 2 cluster centers.\n",
      "Training 28 clusters\n",
      "[MiniBatchKMeans] Reassigning 5 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 3 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 3 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 3 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 2 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 1 cluster centers.\n",
      "[MiniBatchKMeans] Reassigning 3 cluster centers.\n"
     ]
    }
   ],
   "source": [
    "model_locs = []\n",
    "for n_clusters in range(MIN_CLUSTERS, MAX_CLUSTERS, STEP):\n",
    "    print(f\"Training {n_clusters} clusters\")\n",
    "    kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=0, max_iter=MAX_ITER, verbose=1)\n",
    "    for i in range(0, df_recipes_one_hot.shape[0], 10000):\n",
    "        kmeans = kmeans.partial_fit(df_recipes_one_hot[i:i+10000])\n",
    "    filename = f'{ROOT_FOLDER}/trained_kmeans_{n_clusters}_{time.strftime(\"%Y%m%d-%H%M%S\")}.pkl'\n",
    "    pickle.dump(kmeans, open(filename, 'wb'))\n",
    "    model_locs.append(filename)\n",
    "    del kmeans\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34742beb-f8aa-49f9-9f98-1b652f2f6863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../temp_models/trained_kmeans_2_20221117-223707.pkl',\n",
       " '../temp_models/trained_kmeans_4_20221117-223709.pkl',\n",
       " '../temp_models/trained_kmeans_6_20221117-223711.pkl',\n",
       " '../temp_models/trained_kmeans_8_20221117-223713.pkl',\n",
       " '../temp_models/trained_kmeans_10_20221117-223715.pkl',\n",
       " '../temp_models/trained_kmeans_12_20221117-223717.pkl',\n",
       " '../temp_models/trained_kmeans_14_20221117-223719.pkl',\n",
       " '../temp_models/trained_kmeans_16_20221117-223721.pkl',\n",
       " '../temp_models/trained_kmeans_18_20221117-223723.pkl',\n",
       " '../temp_models/trained_kmeans_20_20221117-223725.pkl',\n",
       " '../temp_models/trained_kmeans_22_20221117-223727.pkl',\n",
       " '../temp_models/trained_kmeans_24_20221117-223730.pkl',\n",
       " '../temp_models/trained_kmeans_26_20221117-223732.pkl',\n",
       " '../temp_models/trained_kmeans_28_20221117-223734.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d975661c-6d22-4a88-98b0-0bd3cb86365c",
   "metadata": {},
   "source": [
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6015d38-bef7-435d-b0dc-1b783af2a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample_df = df_recipes_one_hot.sample(n=5000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44bed934-79d6-49b5-8404-387c8409df8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../temp_models/trained_kmeans_2_20221117-223707.pkl -38770.714574583704\n",
      "../temp_models/trained_kmeans_4_20221117-223709.pkl -36168.421819326366\n",
      "../temp_models/trained_kmeans_6_20221117-223711.pkl -35086.00392231671\n",
      "../temp_models/trained_kmeans_8_20221117-223713.pkl -34843.05256679404\n",
      "../temp_models/trained_kmeans_10_20221117-223715.pkl -34386.477152431304\n",
      "../temp_models/trained_kmeans_12_20221117-223717.pkl -34133.12269232504\n",
      "../temp_models/trained_kmeans_14_20221117-223719.pkl -33627.7808503231\n",
      "../temp_models/trained_kmeans_16_20221117-223721.pkl -33463.02081205641\n",
      "../temp_models/trained_kmeans_18_20221117-223723.pkl -33317.28857578833\n",
      "../temp_models/trained_kmeans_20_20221117-223725.pkl -33238.70020138005\n",
      "../temp_models/trained_kmeans_22_20221117-223727.pkl -33022.87582957478\n",
      "../temp_models/trained_kmeans_24_20221117-223730.pkl -32885.23856720834\n",
      "../temp_models/trained_kmeans_26_20221117-223732.pkl -32730.121696977767\n",
      "../temp_models/trained_kmeans_28_20221117-223734.pkl -32565.49527930924\n"
     ]
    }
   ],
   "source": [
    "for filename in model_locs: \n",
    "    kmeans = pickle.load(open(filename, 'rb'))\n",
    "    print(filename, kmeans.score(random_sample_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f80ea9-cbce-4b7d-be2c-389e1dd765f7",
   "metadata": {},
   "source": [
    "# Visualize content of groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c70b14c2-24f1-425f-b17e-f9a0daedbe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_df = pd.read_csv('../data/RAW_recipes.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e10bb7a7-fd6b-48bd-a710-33c3bf859432",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_df['str_name'] = recipe_df['name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "803b8c1c-5027-464b-a596-4d6a1cf94359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_recipes(filename: str):\n",
    "    kmeans = pickle.load(open(filename, 'rb'))\n",
    "    labels = []\n",
    "    for i in range(0, df_recipes_one_hot.shape[0], 10000):\n",
    "       labels.extend(kmeans.predict(df_recipes_one_hot[i:i+10000]))\n",
    "    \n",
    "    df_recipes_with_labels = df_recipes_one_hot.copy()\n",
    "    df_recipes_with_labels[\"label\"] = labels\n",
    "    \n",
    "    labeled_recipes_df = recipe_df.join(df_recipes_with_labels[[\"label\"]])\n",
    "    labels = np.unique(labeled_recipes_df[\"label\"])\n",
    "        \n",
    "    return labeled_recipes_df, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19cf6fbc-c7ad-4bb9-8bd3-263d9a2d2977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordclouds(df, labels):\n",
    "    n_labels = max(labels) + 1\n",
    "    wordclouds = []\n",
    "    for label in labels:\n",
    "        tmp_df = df[df[\"label\"] == label]\n",
    "        names = np.unique(tmp_df[\"str_name\"])\n",
    "        wordcloud = WordCloud(stopwords=STOPWORDS).generate(\" \".join(names))\n",
    "        wordclouds.append(wordcloud)\n",
    "       \n",
    "    plt.figure()\n",
    "    rows = len(labels)//5\n",
    "    if len(labels) % 5 != 0:\n",
    "        rows += 1\n",
    "        \n",
    "    figs, axs = plt.subplots(rows, 5, figsize=(20, 20))\n",
    "    \n",
    "    if rows != 1:\n",
    "        for row in range(rows):\n",
    "            for i in range(5):\n",
    "                axs[row][i].axis(\"off\")\n",
    "\n",
    "        for idx, wordcloud in enumerate(wordclouds):\n",
    "            axs[idx // 5][idx % 5].imshow(wordcloud, interpolation='bilinear')\n",
    "            \n",
    "    else:\n",
    "        for i in range(5):\n",
    "            axs[i].axis(\"off\")\n",
    "            \n",
    "        for idx, wordcloud in enumerate(wordclouds):\n",
    "            axs[idx].axis(\"off\")\n",
    "            axs[idx].imshow(wordcloud, interpolation='bilinear')\n",
    "            \n",
    "    plt.savefig(f'words_{n_labels}.svg',format='svg',bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38dee5eb-4ae0-4dc3-8400-bf97df479f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def create_tree(df, labels):\n",
    "    n_labels = max(labels) + 1\n",
    "    depth = int(math.ceil(math.sqrt(n_labels)))\n",
    "    decision_tree = DecisionTreeClassifier(random_state=0, max_depth=depth).fit(df_recipes_one_hot, df[\"label\"])\n",
    "    \n",
    "    plt.figure(figsize=(depth*10, depth*3))\n",
    "    plot_tree(decision_tree, feature_names=df_recipes_one_hot.columns, filled=True, fontsize=10)\n",
    "    plt.savefig(f'tree_{n_labels}.svg',format='svg',bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e05d102-6728-4126-8824-7f7ad9134ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, file in enumerate(model_locs): \n",
    "    labeled_recipes_df, labels = get_labeled_recipes(file)\n",
    "    labeled_recipes_df.to_pickle(f\"../cleaned_data/labeled_recipes_df_{len(labels)}.pkl\")    \n",
    "    # create_wordclouds(labeled_recipes_df, labels)\n",
    "    # create_tree(labeled_recipes_df, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
